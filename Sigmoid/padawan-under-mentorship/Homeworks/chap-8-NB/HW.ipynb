{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8637297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3cd2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('kidney_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c0e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "### Converting the categorical data to numerical data for the imputer \n",
    "#\n",
    "df['rbc'] = df['rbc'].map({  'normal' : 1 , 'abnormal' : 0}) \n",
    "df['htn'] = df['htn'].map({  'yes' : 1 , 'no' : 0})  \n",
    "df['dm'] = df['dm'].map({  'yes' : 1 , 'no' : 0, '\\tyes' : 1, '\\tno' : 0, ' yes' : 1})  \n",
    "df['cad'] = df['cad'].map({  'yes' : 1 , 'no' : 0, '\\tno' : 0 }) \n",
    "df['appet'] = df['appet'].map({  'good' : 1 , 'poor' : 0, '\\tno' : 0 })  \n",
    "df['pe'] = df['pe'].map({  'yes' : 1 , 'no' : 0})  \n",
    "df['ane'] = df['ane'].map({  'yes' : 1 , 'no' : 0})   \n",
    "df['ba'] = df['ba'].map({  'present' : 1 , 'notpresent' : 0})   \n",
    "df['pc'] = df['pc'].map({  'normal' : 1 , 'abnormal' : 0})  \n",
    "df['pcc'] = df['pcc'].map({  'present' : 1 , 'notpresent' : 0})  \n",
    "\n",
    "# Mapping the feature column to numerical values.\n",
    "df['classification'] = df['classification'].map({  'notckd' : 0 , 'ckd' : 1, 'ckd\\t' :  1 })  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97be9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy vars for categorical data.\n",
    "#df = pd.get_dummies(data=df, columns=[ 'rbc', 'htn', 'dm', 'cad', 'appet','pe','ane','ba', 'pc', 'pcc' ]) \n",
    "\n",
    "\n",
    "\"\"\" \n",
    "    Positioning the dependent column as the last column.\n",
    "\"\"\"\n",
    "# Getting a copy of series of target column\n",
    "temp_target = df['classification']   \n",
    "\n",
    "# Removing the target column at the present position\n",
    "df.pop('classification')  \n",
    "\n",
    "# Adding back  the column target as the last column\n",
    "df.insert(df.shape[1], 'classification', temp_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04bb3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXING THE SAMPLE \n",
    "# Some values were '\\t?' \n",
    "df[(df.values.ravel() == '\\t?').reshape(df.shape).any(1)]  \n",
    "df.iloc[66,16] = np.NAN\n",
    "df.iloc[162,18] = np.NAN  \n",
    "df.iloc[185,17] = np.NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abfd379",
   "metadata": {},
   "source": [
    "## Splitting the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651a9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e475b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0814a",
   "metadata": {},
   "source": [
    "# Importing and assigning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11702407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "s_imputer_mean = SimpleImputer( strategy='mean')  \n",
    "s_imputer_median =  SimpleImputer( strategy='median')  \n",
    "s_imputer_mf = SimpleImputer( strategy='most_frequent')  \n",
    "s_imputer_c = SimpleImputer( strategy='constant', fill_value = 0 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d2166de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer \n",
    "from sklearn.linear_model import LinearRegression \n",
    "it_imputer = IterativeImputer(estimator=LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd26aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer  \n",
    "knn_imputer = KNNImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed994ed",
   "metadata": {},
   "source": [
    "# Assigning training features data for different imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52aaddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nicol\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\impute\\_iterative.py:701: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "X_train_fill_list = list() \n",
    "# 0 \n",
    "X_train_fill_list.append(s_imputer_mean.fit_transform(X_train))   \n",
    "# 1\n",
    "X_train_fill_list.append(s_imputer_median.fit_transform(X_train))   \n",
    "# 2 \n",
    "X_train_fill_list.append(s_imputer_mf.fit_transform(X_train))   \n",
    "# 3 \n",
    "X_train_fill_list.append(s_imputer_c.fit_transform(X_train)) \n",
    "# 4 \n",
    "X_train_fill_list.append(it_imputer.fit_transform(X_train))  \n",
    "# 5 \n",
    "X_train_fill_list.append(knn_imputer.fit_transform(X_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9058a42",
   "metadata": {},
   "source": [
    "# Assigning testing features data for different imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ea72eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fill_list = list() \n",
    "# 0\n",
    "X_test_fill_list.append(s_imputer_mean.transform(X_test))  \n",
    "#1\n",
    "X_test_fill_list.append(s_imputer_median.transform(X_test))  \n",
    "#2\n",
    "X_test_fill_list.append(s_imputer_mf.transform(X_test))  \n",
    "#3\n",
    "X_test_fill_list.append(s_imputer_c.transform(X_test))  \n",
    "#4\n",
    "X_test_fill_list.append(it_imputer.transform(X_test))  \n",
    "#5\n",
    "X_test_fill_list.append(knn_imputer.transform(X_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9fe807",
   "metadata": {},
   "source": [
    "# Standart scaler for X_train and X_test  and dummies vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e02541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbe68d",
   "metadata": {},
   "source": [
    "###### Scaling and assigning the dummies vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b139e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the X_test and X_train. Also getting the dummies for the samples.\n",
    "\n",
    "for i in range( len(X_train_fill_list)):  \n",
    "    \n",
    "    # Scaling\n",
    "    X_train_fill_list[i] = sc.fit_transform(X_train_fill_list[i])  \n",
    "    \n",
    "    # Stroing in a temporary dataframe\n",
    "    temp_df = pd.DataFrame(X_train_fill_list[i], columns = df.columns[:-1] )   \n",
    "    # Getting dummies for catgorical data\n",
    "    temp_df = pd.get_dummies(data=temp_df, columns=[ 'rbc', 'htn', 'dm', 'cad', 'appet','pe','ane','ba', 'pc', 'pcc' ]) \n",
    "    # Assigning back the values of the modified dataframe\n",
    "    X_train_fill_list[i] = temp_df.values[:,:42]\n",
    "    \n",
    "    \n",
    "    # Scaling the X_test\n",
    "    X_test_fill_list[i] = sc.transform(X_test_fill_list[i]) \n",
    "    \n",
    "    # Stroing in a temporary dataframe\n",
    "    temp_df = pd.DataFrame(X_test_fill_list[i], columns = df.columns[:-1] )   \n",
    "    # Getting dummies for catgorical data\n",
    "    temp_df = pd.get_dummies(data=temp_df, columns=[ 'rbc', 'htn', 'dm', 'cad', 'appet','pe','ane','ba', 'pc', 'pcc' ]) \n",
    "    # Assigning back the values of the modified dataframe\n",
    "    X_test_fill_list[i] = temp_df.values[:,:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc18446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a list with Imputer's names\n",
    "method_name= ['Mean Simple Imputer','Median Simple Imputer', 'Most Freq Simple Imputer','Constant Simple Imputer', 'Iterative Imputer','knn Imputer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4c947",
   "metadata": {},
   "source": [
    "# Importing the models and creating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75f86905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_cls = LogisticRegression(random_state = 0)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_cls = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)   \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gauss_cls = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ff20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the column's names\n",
    "\n",
    "df = pd.DataFrame(columns =['ML model', 'Missing value handling technique', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861a1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  accuracy utils\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeb10e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lopping and predicting the results\n",
    "for i in range (len(method_name)):  \n",
    "    \n",
    "    # Logistic Regression \n",
    "    log_cls.fit( X_train_fill_list[i],y_train) \n",
    "    y_pred = log_cls.predict(X_test_fill_list[i]) \n",
    "    a = accuracy_score(y_test, y_pred) \n",
    "    new_row = {  'ML model' : 'LogisticReg',  'Missing value handling technique' : f'{method_name[i]}', 'Accuracy' : a } \n",
    "    df = df.append( new_row, ignore_index=True  )  \n",
    "    \n",
    "    # KNN\n",
    "    knn_cls.fit( X_train_fill_list[i],y_train)  \n",
    "    y_pred = knn_cls.predict(X_test_fill_list[i]) \n",
    "    a = accuracy_score(y_test, y_pred) \n",
    "    new_row = {  'ML model' : 'KNN',  'Missing value handling technique' : f'{method_name[i]}', 'Accuracy' : a } \n",
    "    df = df.append( new_row, ignore_index=True  ) \n",
    "    \n",
    "    # NB\n",
    "    gauss_cls.fit( X_train_fill_list[i],y_train)  \n",
    "    y_pred = gauss_cls.predict(X_test_fill_list[i]) \n",
    "    a = accuracy_score(y_test, y_pred) \n",
    "    new_row = {  'ML model' : 'Naive Bayes',  'Missing value handling technique' : f'{method_name[i]}', 'Accuracy' : a } \n",
    "    df = df.append( new_row, ignore_index=True  ) \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f49892",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e36b7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML model</th>\n",
       "      <th>Missing value handling technique</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>Mean Simple Imputer</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Mean Simple Imputer</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Mean Simple Imputer</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>Median Simple Imputer</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Median Simple Imputer</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Median Simple Imputer</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>Most Freq Simple Imputer</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Most Freq Simple Imputer</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Most Freq Simple Imputer</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>Constant Simple Imputer</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Constant Simple Imputer</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Constant Simple Imputer</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticReg</td>\n",
       "      <td>knn Imputer</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNN</td>\n",
       "      <td>knn Imputer</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>knn Imputer</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ML model Missing value handling technique  Accuracy\n",
       "0   LogisticReg              Mean Simple Imputer     0.990\n",
       "1           KNN              Mean Simple Imputer     0.990\n",
       "2   Naive Bayes              Mean Simple Imputer     0.640\n",
       "3   LogisticReg            Median Simple Imputer     1.000\n",
       "4           KNN            Median Simple Imputer     0.970\n",
       "5   Naive Bayes            Median Simple Imputer     0.960\n",
       "6   LogisticReg         Most Freq Simple Imputer     0.995\n",
       "7           KNN         Most Freq Simple Imputer     0.960\n",
       "8   Naive Bayes         Most Freq Simple Imputer     0.960\n",
       "9   LogisticReg          Constant Simple Imputer     1.000\n",
       "10          KNN          Constant Simple Imputer     0.975\n",
       "11  Naive Bayes          Constant Simple Imputer     0.950\n",
       "12  LogisticReg                Iterative Imputer     1.000\n",
       "13          KNN                Iterative Imputer     0.975\n",
       "14  Naive Bayes                Iterative Imputer     0.850\n",
       "15  LogisticReg                      knn Imputer     0.995\n",
       "16          KNN                      knn Imputer     0.960\n",
       "17  Naive Bayes                      knn Imputer     0.990"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9dfcd",
   "metadata": {},
   "source": [
    "# I reduced the X_train and X_test to 42 features because of an erorr of the LogisticRegression(). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e16dd",
   "metadata": {},
   "source": [
    " # Still there are  really surprisingly  results for predicting just 1/2 of the sample.   \n",
    " \n",
    " #  We can observe just a bad model on NaiveBayes, a 0.64 on Mean Imputer. \n",
    " \n",
    " # It is either good results because of replacing correctly the NaN values, either overfitting, the whole sample has not been reduced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd25c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10332946",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17820/1167623271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mLogR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     def __init__(self,learning_rate : float = 0.05,\n\u001b[0;32m      3\u001b[0m                 max_iter : int = 100000) -> None:\n\u001b[0;32m      4\u001b[0m         \"\"\" \n\u001b[0;32m      5\u001b[0m            \u001b[0mThe\u001b[0m \u001b[0mconstructor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mLogistic\u001b[0m \u001b[0mRegression\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17820/1167623271.py\u001b[0m in \u001b[0;36mLogR\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m  \u001b[1;33m:\u001b[0m \u001b[1;34m'np.array'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'np.array'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mLogR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \"\"\" \n\u001b[0;32m     38\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogR' is not defined"
     ]
    }
   ],
   "source": [
    "class LogR():\n",
    "    def __init__(self,learning_rate : float = 0.05,\n",
    "                max_iter : int = 100000) -> None:\n",
    "        \"\"\" \n",
    "           The constructor of the Logistic Regression model\n",
    "           :param learning_rate: float, default = 0.05 \n",
    "             The learning rate of the model \n",
    "            :param max_iter: int, default = 100 000 \n",
    "             The number of itereation to go through \n",
    "        \"\"\"\n",
    "        \n",
    "        # Setting up the hyperparameters. \n",
    "        self.__learning_rate = learning_rate\n",
    "        self.__max_iter = max_iter \n",
    "    \n",
    "    def sigmoid(self, y: 'np.array') -> 'np.array':\n",
    "        \"\"\"\n",
    "          The sigmoid function.\n",
    "            :param y: np.array \n",
    "              The predcitons of the linear function\n",
    "        \"\"\" \n",
    "        \n",
    "        return 1 / ( 1 + np.exp(-y)) \n",
    "    \n",
    "    \n",
    "    \n",
    "     ########################################\n",
    "    \n",
    "    \n",
    "    #def fit(self,X  : 'np.array', y : 'np.array') -> LogR(): \n",
    "    \n",
    "    \n",
    "    #####################3\n",
    "        \n",
    "    \n",
    "    def fit(self,X  : 'np.array', y : 'np.array') -> LogR:\n",
    "        \"\"\" \n",
    "            The fit function of the model. \n",
    "            :param X: 2-d np.array \n",
    "              The matrix with the features. \n",
    "            :param y: 1-d np.array\n",
    "              The target vector \n",
    "        \"\"\"\n",
    "        \n",
    "        # Creatting the weights vector \n",
    "        self.coef_ = np.zeros(len(X[0]) + 1) \n",
    "        \n",
    "        # Adding the intercept column \n",
    "        X = np.hstack((X, np.ones((len(X), 1 )))) \n",
    "        \n",
    "        # The weights updating process \n",
    "        for i in range(self.__max_iter):\n",
    "            # Prediction.\n",
    "            pred = self.sigmoid(np.dot(X, self.coef_)) \n",
    "            \n",
    "            # Computing the gradient \n",
    "            gradient = np.dot(X.T, (pred - y)) / y.size \n",
    "            \n",
    "            # Updating the weights. \n",
    "            self.coef_ = gradient * self.__learning_rate \n",
    "        return self \n",
    "    \n",
    "    def predict_proba(self, X : 'np.array') -> 'np.array':\n",
    "        \n",
    "        X = np.hstack((X, np.ones((len(X), 1)))) \n",
    "        \n",
    "        prob = self.sigmoid(np.dot(X, self.coef_)) \n",
    "        \n",
    "        return np.hstack(((1 - prob).reshape(-1, 1),\n",
    "                          prob.reshape(-1,1))) \n",
    "    \n",
    "    def predict(self, X : 'np.array') -> 'np.array':\n",
    "        \n",
    "        X = np.hstack((X, np.ones((len(X), 1 )))) \n",
    "        \n",
    "        return (self.sigmoid(np.dot(X, self.coef_)) > 0.5 ) * 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe9694",
   "metadata": {},
   "source": [
    "# ERROR \n",
    "###### am presupus gresit ca e 'np.array'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d970760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('social_ads.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47bf3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data sample.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67799c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = LogR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10f706ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogR at 0x12920b39d48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "669ccbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kek.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "995b7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 68]\n",
      " [ 0 32]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "#initializing the confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "print(cm) \n",
    "#printing the accuracy of the model on the test set.\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68fa33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
